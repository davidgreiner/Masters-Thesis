@article{SoletDJNorvellJMRutanGH2005,
	author = {Solet, DJ and Norvell, JM and Rutan, GH and Frankel, RM.},
	doi = {10.1097/00001888-200512000-00005},
	issn = {1040-2446},
	journal = {Academic Medicine},
	number = {12},
	pages = {1094--1099},
	pmid = {16306279},
	title = {{Lost in translation: challenges and opportunities in physician to physician communication during patient handoff.}},
	volume = {80},
	year = {2005}
}

@article{Meisel2015,
	abstract = {Study objective Patient handoffs are known as high-risk events for medical error but little is known about the professional, structural, and interpersonal factors that can affect the patient transition from emergency medical services (EMS) care to the emergency department (ED). We study EMS providers' perspectives to generate hypotheses to inform and improve this handoff. Methods We conducted focus groups with EMS providers recruited at 3 national and regional conferences from January to March 2011 until theme saturation was reached; 7 focus groups were conducted with 48 EMS providers. Deidentified transcripts and notes were entered into QSR NVivo, coded, and analyzed to identify themes. Results EMS providers identified themselves as advocates for their patients during the challenging EMS-to-ED handoffs. Providers identified normative challenges they encounter in their communications with hospital staff, and features of EMS and hospital protocols that either facilitate or undermine effective handoffs from the out-of-hospital environment to the ED. They identified 4 key potential ways to improve the structure and process of the handoff: (1) communicate directly with the ED provider responsible for the patient's care; (2) increase interdisciplinary feedback, transparency, and shared understanding of scope of practice between out-of-hospital and hospital-based providers; (3) standardize some (but not all) aspects of the handoff; and (4) harness technology to close gaps in information exchange. Conclusion These exploratory findings suggest that the effect of increasing EMS interactions with emergency physicians, standardizing handoff processes, and fostering interprofessional learning represent opportunities for future study and may serve as potential solutions for the high-risk EMS-ED patient transition.},
	author = {Meisel, Zachary F. and Shea, Judy A. and Peacock, Nicholas J. and Dickinson, Edward T. and Paciotti, Breah and Bhatia, Roma and Buharin, Egor and Cannuscio, Carolyn C.},
	doi = {10.1016/j.annemergmed.2014.07.003},
	isbn = {0196-0644},
	issn = {10976760},
	journal = {Annals of Emergency Medicine},
	number = {3},
	pages = {310--317.e1},
	pmid = {25109535},
	publisher = {American College of Emergency Physicians},
	title = {{Optimizing the patient handoff between emergency medical services and the emergency department}},
	url = {http://dx.doi.org/10.1016/j.annemergmed.2014.07.003},
	volume = {65},
	year = {2015}
}

@article{Bhabra2007,
	abstract = {INTRODUCTION: With the increase in shift pattern work for junior doctors in the NHS, accurate handover of patient clinical information is of great importance. There is no published method that forms the gold standard of handover and there are large variations in practice. This study aims to compare the reliability of three different handover methods. PATIENTS AND METHODS: We observed the handover of 12 simulated patients over five consecutive handover cycles between SHOs on a one-to-one basis. Three handover styles were used and a numerical scoring system assessed clinical information lost per handover cycle. RESULTS: After five handover cycles, only 2.5{\%} of patient information was retained using the verbal-only handover method, 85.5{\%} was retained when using the using the verbal with note taking method and 99{\%} was retained when a printed handout containing all patient information was used. CONCLUSIONS: When patient information is handed over by the verbal only method, very few facts are retained; therefore, this method should be avoided whenever possible. Verbal handover with note taking is shown to be an effective method of handover in our study, although we accept that this is an artificial scenario and may not reflect the reality of a busy hospital. Nearly all information is retained by the printed handout method but this relies on the handout being regularly updated.},
	author = {Bhabra, Gevdeep and Mackeith, Samuel and Monteiro, Pedro and Pothier, David D.},
	doi = {10.1308/003588407X168352},
	isbn = {003588407X},
	issn = {00358843},
	journal = {Annals of the Royal College of Surgeons of England},
	keywords = {Communication,Continuity of patient care,Medical staff, hospital,Physicians,Professional practice/standards},
	number = {3},
	pages = {298--300},
	pmid = {17394718},
	title = {{An experimental comparison of handover methods}},
	volume = {89},
	year = {2007}
}

@article{Spencer2004,
	abstract = {Study objective We determine whether there are differences in role-related communication patterns in the emergency department (ED). Methods This was an observational study of a metropolitan ED. Four medical officers and 4 nurses were observed for 19 hours and 52 minutes. Communication load was measured by proportion of observed time in communication, proportion of concurrent communication events, and proportion of interruptions. Results Eight hundred thirty-one communication events were identified, an average of 42 events per person per hour. Eighty-nine percent of clinicians' time was spent in communication. Synchronous communication channels, involving face-to-face or telephone conversations, were used in 84{\%} of events. One third of communication events were classified as interruptions, averaging 15 interruptions per person per hour. Senior medical and nursing staff experienced higher rates of interruption than junior medical staff and registered nurses with an allocated patient load. Conclusion There was considerable variation in communication loads on clinical staff occupying different roles in the ED. Medical registrars had a high proportion of interruptions and spent the most time dealing with interruptions. These new data suggest some clinical roles may be at higher risk of communication overload than those of the general clinical population.},
	author = {Spencer, Rosemary and Coiera, Enrico and Logan, Pamela},
	doi = {10.1016/j.annemergmed.2004.04.006},
	isbn = {1097-6760 (Electronic)$\backslash$n0196-0644 (Linking)},
	issn = {01960644},
	journal = {Annals of Emergency Medicine},
	number = {3},
	pages = {268--273},
	pmid = {12056992},
	title = {{Variation in communication loads on clinical staff in the emergency department}},
	volume = {44},
	year = {2004}
}

@techreport{CRICOStrategies.2015,
	abstract = {For more than 10 years, we have relied on malpractice data from our Comparative Benchmarking System (CBS) partners to identify patient safety risks in the most vulnerable parts of health care delivery. As our 2015 Report demonstrates, errors in communication are common across all care encounters. All providers are susceptible to miscommunicating with other providers or with patients; they are routinely at risk of mismanaging crucial information and instructions; and in doing so can expose patients to preventable harm, and other caregivers to avoidable ramifications stemming from those harms. Our CBS Reports represent an extraordinary partnership among those of you who contribute data, share experiences, inspire analyses, and implement solutions to the problems we uncover. This is your Report. As we explore how we can work together to enhance communication skills and systems for providers in all phases of health care delivery, our collaboration is once again proving to be a vital tool for improving patient safety.},
	address = {Bosten, MA},
	author = {{CRICO Strategies.}},
	institution = {The Risk Management Foundation of the Harvard Medical Institutions Incorporated},
	pages = {24},
	title = {{Malpractice Risks in Communication Failures 2015 Annual Benchmarking Report}},
	year = {2015}
}

@article{Arora2006,
	abstract = {Background: The Joint Commission has made a "standardized approach to hand-off communications" a National Patient Safety Goal. Method: An interactive 90-minute workshop (hand-off clinic) was developed in 2005 to (1) develop a standardized process for the handoff, (2) create a checklist of critical patient content, and (3) plan for dissemination and training. Conclusion: To date, 7 of 10 residency programs have participated. Analysis of these protocols demonstrated that the hand-off process is highly variable and discipline-specific. Although all disciplines required a verbal handoff, because of competing demands, verbal communication did not always occur. In some cases, the transfer of professional responsibility was separated in time and space from the transfer of information. For example, in two cases, patient tasks were assigned to other team members to facilitate timely departure of a postcall resident (to meet resident duty-hour restrictions), but results were not formally communicated to anyone. The hand-off clinic facilitated the incorporation of "closed-loop" communication by requiring that follow-up on these tasks be conveyed to the on-call resident. Discussion: This model for design and implementation can be applied to other health care settings.},
	author = {Arora, Vineet and Johnson, Julie},
	doi = {10.1016/S1553-7250(06)32084-3},
	isbn = {1553-7250 (Print)$\backslash$n1553-7250 (Linking)},
	issn = {15537250},
	journal = {Joint Commission Journal on Quality and Patient Safety},
	number = {11},
	pages = {646--655},
	pmid = {17120925},
	title = {{A model for building a standardized hand-off protocol}},
	volume = {32},
	year = {2006}
}

@article{Lara2013,
	abstract = {Providing accurate and opportune information on people's activities and behaviors is one of the most important tasks in pervasive computing. Innumerable applications can be visualized, for instance, in medical, security, entertainment, and tactical scenarios. Despite human activity recognition (HAR) being an active field for more than a decade, there are still key aspects that, if addressed, would constitute a significant turn in the way people interact with mobile devices. This paper surveys the state of the art in HAR based on wearable sensors. A general architecture is first presented along with a description of the main components of any HAR system. We also propose a two-level taxonomy in accordance to the learning approach (either supervised or semi-supervised) and the response time (either offline or online). Then, the principal issues and challenges are discussed, as well as the main solutions to each one of them. Twenty eight systems are qualitatively evaluated in terms of recognition performance, energy consumption, obtrusiveness, and flexibility, among others. Finally, we present some open problems and ideas that, due to their high relevance, should be addressed in future research.},
	author = {Lara, Oscar D. and Labrador, Miguel A.},
	doi = {10.1109/SURV.2012.110112.00192},
	isbn = {1553-877x},
	issn = {1553-877X},
	journal = {IEEE Communications Surveys {\&} Tutorials},
	number = {3},
	pages = {1192--1209},
	title = {{A Survey on Human Activity Recognition using Wearable Sensors}},
	url = {http://ieeexplore.ieee.org/document/6365160/},
	volume = {15},
	year = {2013}
}

@InProceedings{Kuehne11,
	author= "Kuehne, H. and Jhuang, H. and Garrote, E. and Poggio, T. and Serre, T.",
	title = "{HMDB}: a large video database for human motion recognition",
	booktitle = "Proceedings of the International Conference on Computer Vision (ICCV)",
	year = "2011",
}

@article{Herath2017,
	abstract = {Understanding human actions in visual data is tied to advances in complementary research areas including object recognition, human dynamics, domain adaptation and semantic segmentation. Over the last decade, human action analysis evolved from earlier schemes that are often limited to controlled environments to nowadays advanced solutions that can learn from millions of videos and apply to almost all daily activities. Given the broad range of applications from video surveillance to human–computer interaction, scientific milestones in action recognition are achieved more rapidly, eventually leading to the demise of what used to be good in a short time. This motivated us to provide a comprehensive review of the notable steps taken towards recognizing human actions. To this end, we start our discussion with the pioneering methods that use handcrafted representations, and then, navigate into the realm of deep learning based approaches. We aim to remain objective throughout this survey, touching upon encouraging improvements as well as inevitable fallbacks, in the hope of raising fresh questions and motivating new research directions for the reader.},
	archivePrefix = {arXiv},
	arxivId = {1605.04988},
	author = {Herath, Samitha and Harandi, Mehrtash and Porikli, Fatih},
	doi = {10.1016/j.imavis.2017.01.010},
	eprint = {1605.04988},
	issn = {02628856},
	journal = {Image and Vision Computing},
	keywords = {Deep networks,Human action recognition,Motion recognition,Survey},
	pages = {4--21},
	publisher = {Elsevier B.V.},
	title = {{Going deeper into action recognition: A survey}},
	url = {http://dx.doi.org/10.1016/j.imavis.2017.01.010},
	volume = {60},
	year = {2017}
}

@article{Wannenburg2016,
	abstract = {Physical activity recognition of everyday activities such as sitting, standing, laying, walking, and jogging was performed, through the use of smartphone accelerometer data. Activity classification was done on a remote server through the use of machine learning algorithms, data was received from the smartphone wirelessly. The smartphone was placed in the subject's trouser pocket while data was gathered. A large sample set was used to train the classifiers and then a test set was used to verify the algorithm accuracies. Ten different classifier algorithm configurations were evaluated to determine which performed best overall, as well as, which algorithms performed best for specific activity classes. Based on the results obtained, very accurate predictions could be made for offline activity recognition. The kNN and kStar algorithms both obtained an overall accuracy of 99.01{\%}.},
	author = {Wannenburg, Johan and Malekian, Reza},
	doi = {10.1109/TSMC.2016.2562509},
	issn = {2168-2216},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	number = {12},
	pages = {1--8},
	title = {{Physical Activity Recognition From Smartphone Accelerometer Data for User Context Awareness Sensing}},
	url = {http://ieeexplore.ieee.org/document/7476869/},
	volume = {47},
	year = {2016}
}

@article{Starmer2014,
	author = { Starmer, Amy J. and Spector,  Nancy D.  and  Srivastava ,  Rajendu  and  West ,  Daniel C.  and  Rosenbluth ,  Glenn  and  Allen ,  April D.  and  Noble ,  Elizabeth L.  and  Tse ,  Lisa L.  and  Dalal ,  Anuj K.  and  Keohane ,  Carol A.  and  Lipsitz ,  Stuart R.  and  Rothschild ,  Jeffrey M.  and  Wien ,  Matthew F.  and  Yoon ,  Catherine S.  and  Zigmont ,  Katherine R.  and  Wilson ,  Karen M.  and  O’Toole ,  Jennifer K.  and  Solan ,  Lauren G.  and  Aylor ,  Megan  and  Bismilla ,  Zia  and  Coffey ,  Maitreya  and  Mahant ,  Sanjay  and  Blankenburg ,  Rebecca L.  and  Destino ,  Lauren A.  and  Everhart ,  Jennifer L.  and  Patel ,  Shilpa J.  and  Bale ,  James F.   Jr.  and  Spackman ,  Jaime B.  and  Stevenson ,  Adam T.  and  Calaman ,  Sharon  and  Cole ,  F. Sessions  and  Balmer ,  Dorene F.  and  Hepps ,  Jennifer H.  and  Lopreiato ,  Joseph O.  and  Yu ,  Clifton E.  and  Sectish ,  Theodore C.  and  Landrigan ,  Christopher P. },
	title = {Changes in Medical Errors after Implementation of a Handoff Program},
	journal = {New England Journal of Medicine},
	volume = {371},
	number = {19},
	pages = {1803-1812},
	year = {2014},
	doi = {10.1056/NEJMsa1405556},
	note ={PMID: 25372088},
	URL = {http://dx.doi.org/10.1056/NEJMsa1405556},
	eprint = { http://dx.doi.org/10.1056/NEJMsa1405556}
}

@article{COLLINS2011704,
	title = {Content overlap in nurse and physician handoff artifacts and the potential role of electronic health records: A systematic review},
	journal = {Journal of Biomedical Informatics},
	volume = {44},
	number = {4},
	pages = {704--712},
	year = {2011},
	issn = {1532-0464},
	doi = {https://doi.org/10.1016/j.jbi.2011.01.013},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046411000153},
	author = {Sarah A. Collins and Daniel M. Stein and David K. Vawdrey and Peter D. Stetson and Suzanne Bakken},
	keywords = {Handoff(s), Hand-off, Handover(s), Shift-report, Signout and Sign-out, Interdisciplinary, Electronic health records}
}

@article{Poppe2010,
	abstract = {Vision-based human action recognition is the process of labeling image sequences with action labels. Robust solutions to this problem have applications in domains such as visual surveillance, video retrieval and human-computer interaction. The task is challenging due to variations in motion performance, recording settings and inter-personal differences. In this survey, we explicitly address these challenges. We provide a detailed overview of current advances in the field. Image representations and the subsequent classification process are discussed separately to focus on the novelties of recent research. Moreover, we discuss limitations of the state of the art and outline promising directions of research. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
	author = {Poppe, Ronald},
	doi = {10.1016/j.imavis.2009.11.014},
	isbn = {0262-8856},
	issn = {02628856},
	journal = {Image and Vision Computing},
	keywords = {Action detection,Human action recognition,Motion analysis},
	mendeley-groups = {Human Activity Recognition},
	number = {6},
	pages = {976--990},
	publisher = {Elsevier B.V.},
	title = {{A survey on vision-based human action recognition}},
	url = {http://dx.doi.org/10.1016/j.imavis.2009.11.014},
	volume = {28},
	year = {2010}
}

@article{Bobick2001,
	author = {A. F. Bobick and J. W. Davis},
	journal = {IEEE Transactions on Pattern Analysis {\&} Machine Intelligence},
	title = {The Recognition of Human Movement Using Temporal Templates},
	year = {2001},
	volume = {23},
	pages = {257-267},
	keywords={Motion recognition; computer vision.},
	doi = {10.1109/34.910878},
	url = {doi.ieeecomputersociety.org/10.1109/34.910878},
	ISSN = {0162-8828},
	month={03}
}

@article{Weinland2006,
	abstract = {Action recognition is an important and challenging topic in computer vision, with many important applications including video surveillance, automated cinematography and understanding of social interaction. Yet, most current work in gesture or action interpretation remains rooted in view-dependent representations. This paper introduces Motion History Volumes (MHV) as a free-viewpoint representation for human actions in the case of multiple calibrated, and background-subtracted, video cameras. We present algorithms for computing, aligning and comparing MHVs of different actions performed by different people in a variety of viewpoints. Alignment and comparisons are performed efficiently using Fourier transforms in cylindrical coordinates around the vertical axis. Results indicate that this representation can be used to learn and recognize basic human action classes, independently of gender, body size and viewpoint. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
	author = {Weinland, Daniel and Ronfard, Remi and Boyer, Edmond},
	doi = {10.1016/j.cviu.2006.07.013},
	isbn = {1077-3142},
	issn = {10773142},
	journal = {Computer Vision and Image Understanding},
	keywords = {Action recognition,View invariance,Volumetric reconstruction},
	number = {2-3 SPEC. ISS.},
	pages = {249--257},
	title = {{Free viewpoint action recognition using motion history volumes}},
	volume = {104},
	year = {2006}
}

@inproceedings{Efros03, 
	title = {Recognizing Action at a Distance}, 
	author = {Alexei A. Efros and Alexander C. Berg and Greg Mori and
	Jitendra Malik}, 
	pages = {726--733}, 
	booktitle = {IEEE International Conference on Computer Vision}, 
	address = {Nice, France}, 
	year = 2003
}

@article{CGV-005,
	url = {http://dx.doi.org/10.1561/0600000005},
	year = {2006},
	volume = {1},
	journal = {Foundations and Trends in Computer Graphics and Vision},
	title = {Computational Studies of Human Motion: Part 1, Tracking and Motion Synthesis},
	doi = {10.1561/0600000005},
	issn = {1572-2740},
	number = {2--3},
	pages = {77--254},
	author = {David A. Forsyth and Okan Arikan and Leslie Ikemoto and James O'Brien and Deva Ramanan}
}

@article{Maurer2006,
	author = {Maurer, U. and Smailagic, A. and Siewiorek, D.P. and Deisher, M.},
	doi = {10.1109/BSN.2006.6},
	isbn = {0-7695-2547-4},
	journal = {International Workshop on Wearable and Implantable Body Sensor Networks (BSN)},
	pages = {113--116},
	title = {{Activity Recognition and Monitoring Using Multiple Sensors on Different Body Positions}},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1612909},
	year = {2006}
}

@article{Lara2012,
	abstract = {This paper presents Centinela, a system that combines acceleration data with vital signs to achieve highly accurate activity recognition. Centinela recognizes five activities: walking, running, sitting, ascending, and descending. The system includes a portable and unobtrusive real-time data collection platform, which only requires a single sensing device and a mobile phone. To extract features, both statistical and structural detectors are applied, and two new features are proposed to discriminate among activities during periods of vital sign stabilization. After evaluating eight different classifiers and three different time window sizes, our results show that Centinela achieves up to 95.7{\%} overall accuracy, which is higher than current approaches under similar conditions. Our results also indicate that vital signs are useful to discriminate between certain activities. Indeed, Centinela achieves 100{\%} accuracy for activities such as running and sitting, and slightly improves the classification accuracy for ascending compared to the cases that utilize acceleration data only. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
	author = {Lara, {\'{O}}scar D. and Prez, Alfredo J. and Labrador, Miguel A. and Posada, Jos D.},
	doi = {10.1016/j.pmcj.2011.06.004},
	isbn = {1574-1192},
	issn = {15741192},
	journal = {Pervasive and Mobile Computing},
	keywords = {Classification,Feature extraction,Subject-independent analysis,Transient features},
	number = {5},
	pages = {717--729},
	publisher = {Elsevier B.V.},
	title = {{Centinela: A human activity recognition system based on acceleration and vital sign data}},
	url = {http://dx.doi.org/10.1016/j.pmcj.2011.06.004},
	volume = {8},
	year = {2012}
}

@article{Rodgers2015,
	abstract = {— Wearable sensor technology continues to advance and provide significant opportunities for improving personalized healthcare. In recent years, advances in flexible electronics, smart materials, and low-power computing and networking have reduced barriers to technology accessibility, integration, and cost, unleashing the potential for ubiquitous monitoring. This paper discusses recent advances in wearable sensors and systems that monitor movement, physiology, and environment, with a focus on applications for Parkinson's disease, stroke, and head and neck injuries.},
	author = {Rodgers, Mary M. and Pai, Vinay M. and Conroy, Richard S.},
	doi = {10.1109/JSEN.2014.2357257},
	isbn = {1530-437X VO - 15},
	issn = {1530437X},
	journal = {IEEE Sensors Journal},
	number = {6},
	pages = {3119--3126},
	title = {{Recent advances in wearable sensors for health monitoring}},
	volume = {15},
	year = {2015}
}

@Misc{openpose,
	author =   {Gines, Hidalgo and Zhe, Cao and Tomas, Simon and Shih-En, Wei and Hanbyul, Joo and Yaser Sheikh.},
	title =    {OpenPose: Real-time multi-person keypoint detection library for body, face, and hands estimation},
	howpublished = {\url{https://github.com/CMU-Perceptual-Computing-Lab/openpose}},
	year = {2017--2018},
	note = {Accessed on 03/02/2018}
}
@InProceedings{Arning2015,
	author="Arning, Katrin
	and Ziefle, Martina",
	editor="Geissb{\"u}hler, Antoine
	and Demongeot, Jacques
	and Mokhtari, Mounir
	and Abdulrazak, Bessam
	and Aloulou, Hamdi",
	title="``Get that Camera Out of My House!'' Conjoint Measurement of Preferences for Video-Based Healthcare Monitoring Systems in Private and Public Places",
	booktitle="Inclusive Smart Cities and e-Health",
	year="2015",
	publisher="Springer International Publishing",
	address="Cham",
	pages="152--164",
	abstract="Facing the healthcare challenges of an aging society, the expansion of AAL system implementation in private and public environments is a promising way to improve healthcare in future smart homes and cities. The present study evaluated preferences for different video-based medical monitoring scenarios, which comprised the attributes medical safety (improved detection of medical emergencies), privacy (handling of video information), type and location of camera in a conjoint analysis. Medical safety was identified as key driver for preferences. Acceptance for video-based medical monitoring systems in public places was comparably high, given that privacy was protected. In contrast, acceptance for video-based monitoring in smart home environments was rather low due to privacy concerns. Based on the findings, recommendation for AAL system design and implementation were derived.",
	isbn="978-3-319-19312-0"
}

@Misc{privacyindex,
	author =   {TRUSTe/NCSA},
	title =    {U.S. Consumer Privacy Index 2016},
	howpublished = {\url{https://www.trustarc.com/resources/privacy-research/ncsa-consumer-privacy-index-us/}},
	year = {2016},
	note = {Accessed on 03/02/2018}
}


@article{Smykla2016,
	abstract = {Many people are enthusiastic about the potential benefits of police body-worn cameras (BWC). Despite this enthusiasm, however, there has been no research on law enforcement command staff perceptions of BWCs. Given the importance that law enforcement leadership plays in the decision to adopt and implement BWCs, it is necessary to assess their perceptions. This is the first study to measure law enforcement leadership attitudes toward BWCs. The study relies on data collected from surveys administered to command staff representing local, state and federal law enforcement agencies in a large southern county. Among the major perceptual findings are that command staff believe BWCs will impact police officers' decisions to use force in encounters with citizens and police will be more reluctant to use necessary force in encounters with the public. Respondents also believe that use of BWCs is supported by the public because society does not trust police, media will use BWC data to embarrass police, and pressure to implement BWCs comes from the media. Perceptions of the impact of BWCs on safety, privacy, and police effectiveness are also discussed.},
	author = {Smykla, John Ortiz and Crow, Matthew S. and Crichlow, Vaughn J. and Snyder, Jamie A.},
	doi = {10.1007/s12103-015-9316-4},
	issn = {19361351},
	journal = {American Journal of Criminal Justice},
	keywords = {Body-worn cameras,Police leadership perceptions,Police survey,Policing,Technology},
	number = {3},
	pages = {424--443},
	publisher = {American Journal of Criminal Justice},
	title = {{Police Body-Worn Cameras: Perceptions of Law Enforcement Leadership}},
	url = {http://dx.doi.org/10.1007/s12103-015-9316-4},
	volume = {41},
	year = {2016}
}

@article{Cohen2010,
	abstract = {In hospitals, handoffs are episodes in which control of, or responsibility for, a patient passes from one health professional to another, and in which important information about the patient is also exchanged. In view of the growing interest in improving handoff processes, and the need for guidance in arriving at standardised handoff procedures in response to regulatory requirements, an extensive review of the research on handoffs was conducted.},
	author = {Cohen, Michael D. and Hilligoss, P. Brian},
	doi = {10.1136/qshc.2009.033480},
	isbn = {1475-3901 (Electronic) 1475-3898 (Linking)},
	issn = {14753898},
	journal = {Quality and Safety in Health Care},
	number = {6},
	pages = {493--497},
	pmid = {20378628},
	title = {{The published literature on handoffs in hospitals: Deficiencies identified in an extensive review}},
	volume = {19},
	year = {2010}
}

@ARTICLE{Helal2010,
	author = {S. Helal and E. Kim and D. Cook},
	journal = {IEEE Pervasive Computing},
	title = {Human Activity Recognition and Pattern Discovery},
	year = {2010},
	volume = {9},
	number = {},
	pages = {48-53},
	keywords={activity modeling; activity recognition; pattern discovery; pervasive computing},
	doi = {10.1109/MPRV.2010.7},
	url = {doi.ieeecomputersociety.org/10.1109/MPRV.2010.7},
	ISSN = {1536-1268},
	month={01}
}

@InProceedings{Dorfmeister2014,
	author="Maier, Marco
	and Dorfmeister, Florian",
	editor="Memmi, G{\'e}rard
	and Blanke, Ulf",
	title="Fine-Grained Activity Recognition of Pedestrians Travelling by Subway",
	booktitle="Mobile Computing, Applications, and Services",
	year="2014",
	publisher="Springer International Publishing",
	address="Cham",
	pages="122--139",
	abstract="With the now widespread usage of increasingly powerful smartphones, pro-active, context-aware, and thereby unobstrusive applications have become possible. A user's current activity is a primary piece of contextual information, and especially in urban areas, a user's current mode of transport is an important part of her activity. A lot of research has been conducted on automatically recognizing different means of transport, but up to know, no attempt has been made to perform a fine-grained classification of different activities related to travelling by local public transport.",
	isbn="978-3-319-05452-0"
}

@article{Benalcazar2017,
	author = {Benalc{\'{a}}zar, Marco E and Jaramillo, Andr{\'{e}}s G and Zea, A and P{\'{a}}ez, Andr{\'{e}}s},
	doi = {10.23919/EUSIPCO.2017.8081366},
	isbn = {9780992862671},
	journal = {2017 25th European Signal Processing Conference},
	keywords = {dynamic time warping algorithm,emg,hand gesture recogntion,k-nearest neighbor,learning,machine},
	pages = {1075--1079},
	title = {{Hand Gesture Recognition Using Machine Learning and the Myo Armband}},
	year = {2017}
}

@article{FAABOS,
	author = {Uswatte, Gitendra and Qadri, Laura},
	year = {2009},
	month = {11},
	pages = {398-403},
	title = {A Behavioral Observation System for Quantifying Arm Activity in Daily Life After Stroke},
	volume = {54},
	booktitle = {Rehabilitation psychology}
}

@article{Totty2017,
	author = {Totty, Michael S. and Wade, Eric},
	doi = {10.1109/TBME.2017.2738440},
	issn = {0018-9294},
	journal = {IEEE Transactions on Biomedical Engineering},
	number = {c},
	pages = {1--1},
	title = {{Muscle Activation and Inertial Motion Data for Non-Invasive Classification of Activities of Daily Living}},
	url = {http://ieeexplore.ieee.org/document/8007300/},
	volume = {9294},
	year = {2017}
}

@article{Ahmad2013,
	abstract = {— Inertial Measurement Unit (IMU) sensors are used widely in many different movable applications. Across many years, the improvements and applications of IMU have increased through various areas such as manufacturing, navigation, and robotics. This paper presents a literature review of several current IMU categories and applications. A few considerations on choosing an IMU for different applications are summarized and current methods being used to improve the accuracy of the output from IMU are also presented to avoid the errors that latest IMU is facing. Improvement methods include the control algorithms and type of filters for the sensor. Pros and cons of the types and algorithms used are also discussed in relation to different applications.  Index Terms— gyroscope, magnetometer, accelerometer, IMU},
	author = {Ahmad, Norhafizan and Ghazilla, Raja Ariffin Raja and Khairi, Nazirah M. and Kasi, Vijayabaskar},
	doi = {10.12720/ijsps.1.2.256-262},
	isbn = {23154535},
	issn = {23154535},
	journal = {International Journal of Signal Processing Systems},
	number = {2},
	pages = {256--262},
	title = {{Reviews on Various Inertial Measurement Unit (IMU) Sensor Applications}},
	url = {http://www.ijsps.com/index.php?m=content{\&}c=index{\&}a=show{\&}catid=32{\&}id=65},
	volume = {1},
	year = {2013}
}

@InProceedings{Dirk2010,
	author="Gehrig, Dirk
	and Stein, Thorsten
	and Fischer, Andreas
	and Schwameder, Hermann
	and Schultz, Tanja",
	editor="Dillmann, R{\"u}diger
	and Beyerer, J{\"u}rgen
	and Hanebeck, Uwe D.
	and Schultz, Tanja",
	title="Towards Semantic Segmentation of Human Motion Sequences",
	booktitle="KI 2010: Advances in Artificial Intelligence",
	year="2010",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="436--443",
	abstract="In robotics research is an increasing need for knowledge about human motions. However humans tend to perceive motion in terms of discrete motion primitives. Most systems use data-driven motion segmentation to retrieve motion primitives. Besides that the actual intention and context of the motion is not taken into account. In our work we propose a procedure for segmenting motions according to their functional goals, which allows a structuring and modeling of functional motion primitives. The manual procedure is the first step towards an automatic functional motion representation. This procedure is useful for applications such as imitation learning and human motion recognition. We applied the proposed procedure on several motion sequences and built a motion recognition system based on manually segmented motion capture data. We got a motion primitive error rate of 0.9Â {\%} for the marker-based recognition. Consequently the proposed procedure yields motion primitives that are suitable for human motion recognition.",
	isbn="978-3-642-16111-7"
}

@article{Schrempf2005,
	abstract = {The recognition of user intentions is an important feature for humanoid$\backslash$nrobots to make implicit and human-like interactions possible. In$\backslash$nthis paper, we introduce a formal view on user-intentions in human-machine$\backslash$ninteraction and how they can be estimated by observing user actions.$\backslash$nWe use Hybrid Dynamic Bayesian Networks to develop a generic model$\backslash$nthat includes connections between intentions, actions, and sensor$\backslash$nmeasurements. This model can be used to extend arbitrary human-machine$\backslash$napplications by intention recognition.},
	author = {Schrempf, Oliver C and Hanebeck, Uwe D},
	journal = {Proceedings of the 2nd International Conference on Informatics in Control, Automation and Robotics (ICINCO 2005)},
	keywords = {Intention Recognition},
	pages = {251--256},
	title = {{A Generic Model for Estimating User Intentions in Human-Robot Cooperation}},
	volume = {3},
	year = {2005}
}

@article{Gehrig2011,
	abstract = {In this paper, a multi-level approach to intention, activity, and$\backslash$nmotion recognition for a humanoid robot is proposed. Our system processes$\backslash$nimages from a monocular camera and combines this information with$\backslash$ndomain knowledge. The recognition works on-line and in real-time,$\backslash$nit is independent of the test person, but limited to predefined view-points.$\backslash$nMain contributions of this paper are the extensible, multi-level$\backslash$nmodeling of the robot's vision system, the efficient activity and$\backslash$nmotion recognition, and the asynchronous information fusion based$\backslash$non generic processing of mid-level recognition results. The complementarity$\backslash$nof the activity and motion recognition renders the approach robust$\backslash$nagainst misclassifications. Experimental results on a real-world$\backslash$ndata set of complex kitchen tasks, e.g., Prepare Cereals or Lay Table,$\backslash$nprove the performance and robustness of the multi-level recognition$\backslash$napproach.},
	author = {Gehrig, Dirk and Krauthausen, Peter and Rybok, Lukas and K{\"{u}}hne, Hildegard and Schultz, Tanja and Hanebeck, Uwe D and Stiefelhagen, Rainer},
	doi = {10.1109/IROS.2011.6095118},
	file = {:Volumes/HDD/davidgreiner/Downloads/IROS11{\_}Gehrig.pdf:pdf},
	isbn = {9781612844565},
	issn = {2153-0858},
	journal = {Proceedings of the 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011) (to appear)},
	keywords = {Computer Vision,Humanoid Robots,Recognition},
	mendeley-groups = {Intention Recognition},
	pages = {4819--4825},
	title = {{Combined Multi-Level Intention, Activity, and Motion Recognition for a Humanoid Robot (preliminary)}},
	year = {2011}
}

@article{Zhang2013,
	abstract = {Human daily activity recognition using mobile personal sensing technology plays a central role in the field of pervasive healthcare. One major challenge lies in the inherent complexity of human body movements and the variety of styles when people perform a certain activity. To tackle this problem, in this paper, we present a novel human activity recognition framework based on recently developed compressed sensing and sparse representation theory using wearable inertial sensors. Our approach represents human activity signals as a sparse linear combination of activity signals from all activity classes in the training set. The class membership of the activity signal is determined by solving a l(1) minimization problem. We experimentally validate the effectiveness of our sparse representation-based approach by recognizing nine most common human daily activities performed by 14 subjects. Our approach achieves a maximum recognition rate of 96.1{\%}, which beats conventional methods based on nearest neighbor, naive Bayes, and support vector machine by as much as 6.7{\%}. Furthermore, we demonstrate that by using random projection, the task of looking for “optimal features” to achieve the best activity recognition performance is less important within our framework.},
	author = {Zhang, Mi and Sawchuk, Alexander A.},
	doi = {10.1109/JBHI.2013.2253613},
	isbn = {2168-2194},
	issn = {21682194},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	keywords = {Compressed sensing,Human activity recognition,Pervasive healthcare,Sparse representation,Wearable computing},
	number = {3},
	pages = {553--560},
	pmid = {24592458},
	title = {{Human daily activity recognition with sparse representation using wearable sensors}},
	volume = {17},
	year = {2013}
}

















